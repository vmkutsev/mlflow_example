# Отчёт по экспериментам — homework_egorova

**Датасет:** Adult Census Income (`scikit-learn/adult-census-income`)  
**Задача:** бинарная классификация (доход >50K или ≤50K)  
**Эксперимент в MLflow:** [`homework_egorova`](http://158.160.2.37:5000/#/experiments/10)  
**Ключевая метрика:** ROC-AUC

---

## Разрез 1 — Размер обучающей выборки

**Гипотеза:** увеличение размера датасета монотонно увеличивает ROC-AUC, однако прирост замедляется при больших объёмах данных.

**Фиксировано:** LogisticRegression, фиксированный набор признаков  
**Параметр:** `train_size` ∈ {2 000, 4 000, 8 000, 16 000}

| train_size | ROC-AUC |
|---|---|
| 2 000 | 0.723 |
| 4 000 | 0.724 |
| 8 000 | **0.728** |
| 16 000 | 0.726 |

**Вывод:** гипотеза не подтвердилась. Метрика почти сразу выходит на плато. Обусловлено низкой сложностью модели.

---

## Разрез 2 — Тип модели

**Гипотеза:** ансамблевые модели (RandomForest, GradientBoosting) покажут более высокий ROC-AUC по сравнению с LogisticRegression.

**Фиксировано:** `train_size = 8 000`, фиксированный набор признаков  
**Параметр:** тип классификатора

| Модель | ROC-AUC |
|---|---|
| LogisticRegression | 0.728 |
| RandomForest | 0.820 |
| GradientBoosting | **0.844** |

**Вывод:** гипотеза подтвердилась. Ансамблевые методы существенно превосходят LR: GradientBoosting даёт прирост +0.116 по ROC-AUC. Характерно, что абсолютные значения метрик заметно ниже, чем в нашем эксперименте (0.844 vs 0.921 у GB) — вероятно, из-за более бедного набора признаков.

---

## Разрез 3 — Learning rate GradientBoosting

**Гипотеза:** существует оптимальный `learning_rate`; слишком малые значения приводят к недообучению, слишком большие — к ухудшению качества.

**Фиксировано:** GradientBoostingClassifier, `train_size = 8 000`, фиксированный набор признаков  
**Параметр:** `learning_rate` ∈ {0.01, 0.05, 0.1, 0.2}

| learning_rate | ROC-AUC |
|---|---|
| 0.01 | 0.816 |
| 0.05 | 0.841 |
| 0.1 | 0.844 |
| 0.2 | **0.844** |

**Вывод:** гипотеза подтвердилась частично. Недообучение при `learning_rate = 0.01` очевидно. При росте параметра качество монотонно улучшается, однако ухудшения в диапазоне 0.01–0.2 не наблюдается — оптимум, вероятно, находится за пределами исследованного диапазона.

---

## Лучший запуск

**GradientBoostingClassifier** — ROC-AUC = **0.844**  
`learning_rate=0.2`, `train_size=8 000`

[Открыть в MLflow UI](http://158.160.2.37:5000/#/experiments/10/runs/1a98234586264e5eba4af2a08d8a8f75)
